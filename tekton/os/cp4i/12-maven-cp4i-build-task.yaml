apiVersion: tekton.dev/v1beta1
kind: Task
#
# This task builds the main application, runs the unit tests, runs the component
# tests, and builds two images: the first is the main application image, and the
# second is the component test image (built using the first image as the base).
#
# The second image is not used in this task and is intended to be run in CP4i by
# the next task. Component tests are run in this task as well but do not use the
# CP4i-style configuration mechanism, so verification in CP4i is needed also.
#
metadata:
  name: maven-cp4i-build
  namespace: cp4i
spec:
  # The security and environment settings are needed for OpenShift in a non-default
  # namespace such as cp4i. Kaniko is expecting to be root in the container.
  stepTemplate:
    securityContext:
      runAsUser: 0
    env:
      - name: "HOME"
        value: "/tekton/home"
  params:
    - name: dockerRegistry
      type: string
    - name: url
      type: string
    - name: revision
      type: string
    - name: buildImage
      type: string
    - name: runtimeImage
      type: string
  steps:
    - name: clone
      image: gcr.io/tekton-releases/github.com/tektoncd/pipeline/cmd/git-init:v0.18.1
      #
      # The script just clones the repo but could be extended.
      # 
      script: |
        #!/bin/sh
        cd /work
        git clone -b $(params.revision) $(params.url)
      volumeMounts:
        - mountPath: /work
          name: work
    - name: maven-build
      image: $(params.dockerRegistry)/$(params.buildImage)
      #
      # Runs the build and unit test phases, leaving the results in the work directory
      # for later steps.
      #
      script: |
        #!/bin/bash
        export LICENSE=accept
        . /opt/ibm/ace-12/server/bin/mqsiprofile
        export PATH=/opt/ibm/ace-12/common/jdk/bin:$PATH
        which javac
        javac -version
        mkdir /work/maven-output
        cd /work/ace-demo-pipeline
        mvn --no-transfer-progress -Dinstall.work.directory=/work/maven-output/ace-server install
      volumeMounts:
        - mountPath: /work
          name: work
    - name: container-setup
      image: $(params.dockerRegistry)/$(params.buildImage)
      #
      # Copies files around and changes permissions to allow Kaniko to build the actual
      # runtime image in the next step. Also copies the Dockerfile into place for Kaniko.
      #
      script: |
        #!/bin/bash
        cd /work/maven-output
        cp /work/ace-demo-pipeline/tekton/os/cp4i/Dockerfile Dockerfile
        # Fix permissions issues 
        chmod 777 /work/maven-output /work/maven-output/Dockerfile
        chmod -R a+r /work/maven-output
        find /work/maven-output -type d -print | xargs chmod 775
        ls -l /work/maven-output
      volumeMounts:
        - mountPath: /work
          name: work
    - name: docker-build-and-push
      #image: quay.io/buildah/stable:v1
      image: registry.redhat.io/rhel8/buildah
      securityContext:
        runAsUser: 0
        capabilities:
          add: ["CHOWN", "DAC_OVERRIDE","FOWNER","SETFCAP","SETGID","SETUID"]
      # specifying DOCKER_CONFIG is required to allow buildah to detect docker credential
      env:
        - name: "DOCKER_CONFIG"
          value: "/tekton/home/.docker/"
      script: |
        buildah --storage-driver=overlay bud --format=oci --tls-verify=false --no-cache \
          --build-arg BASE_IMAGE=$(params.dockerRegistry)/$(params.runtimeImage) \
          -f /work/maven-output/Dockerfile -t $(params.dockerRegistry)/tea-tekton-cp4i /work/maven-output
        buildah  --storage-driver=overlay push --tls-verify=false --digestfile /tmp/image-digest \
          $(params.dockerRegistry)/tea-tekton-cp4i  "docker://$(params.dockerRegistry)/tea-tekton-cp4i"
        printf '%s' "$(params.dockerRegistry)/tea-tekton-cp4i"
      volumeMounts:
        - mountPath: /work
          name: work
        - name: varlibcontainers
          mountPath: /var/lib/containers
    - name: component-test
      image: $(params.dockerRegistry)/$(params.buildImage)
      #
      # Builds and runs the component tests using the JDBC credentials provided from
      # the secret. Also uses the same init-creds.sh script used by the non-CP4i image
      # to load credentials at startup.
      #
      # Leaves the resulting component test project in the work directory to be picked
      # up by the second Kaniko build in the next step.
      #
      script: |
        #!/bin/bash
        export LICENSE=accept
        . /opt/ibm/ace-12/server/bin/mqsiprofile
        export PATH=/opt/ibm/ace-12/common/jdk/bin:$PATH
        # Slightly hacky, but quicker than building everything again!
        (cd /work/maven-output/ace-server/run && tar -cf - * ) | (cd /home/aceuser/ace-server/run && tar -xf - )
        ls -l /home/aceuser/ace-server
        # Set up credentials for the component tests; init-creds.sh looks in /tmp for policy
        cp /work/ace-demo-pipeline/demo-infrastructure/TEAJDBC.policyxml /tmp/
        bash /work/ace-demo-pipeline/demo-infrastructure/init-creds.sh
        # Build and run the tests
        cd /work/ace-demo-pipeline/TeaRESTApplication_ComponentTest
        mvn --no-transfer-progress -Dct.work.directory=/home/aceuser/ace-server verify
        # Slightly hacky, but quicker than building everything again!
        (cd /home/aceuser/ace-server/run && tar -cf - * ) | (cd /work/maven-output/ace-server/run && tar -xf - )
      volumeMounts:
        - mountPath: /work
          name: work
        - name: secret-volume-2
          mountPath: /var/run/secrets/jdbc
    - name: container-setup-ct
      image: $(params.dockerRegistry)/$(params.buildImage)
      #
      # Copies files around and changes permissions to allow Kaniko to build the component
      # test image in the next step. Also copies the Dockerfile into place for Kaniko.
      #
      script: |
        #!/bin/bash
        cd /work/maven-output
        cp /work/ace-demo-pipeline/tekton/os/cp4i/Dockerfile Dockerfile
        # Fix permissions issues 
        chmod 777 /work/maven-output /work/maven-output/Dockerfile
        chmod -R a+r /work/maven-output
        find /work/maven-output -type d -print | xargs chmod 775
        ls -l /work/maven-output/ace-server/run
      volumeMounts:
        - mountPath: /work
          name: work
    - name: docker-build-and-push-ct
      #image: quay.io/buildah/stable:v1
      image: registry.redhat.io/rhel8/buildah
      securityContext:
        runAsUser: 0
        capabilities:
          add: ["CHOWN", "DAC_OVERRIDE","FOWNER","SETFCAP","SETGID","SETUID"]
      # specifying DOCKER_CONFIG is required to allow buildah to detect docker credential
      env:
        - name: "DOCKER_CONFIG"
          value: "/tekton/home/.docker/"
      script: |
        buildah --storage-driver=overlay bud --format=oci --tls-verify=false --no-cache \
          --build-arg BASE_IMAGE=$(params.dockerRegistry)/tea-tekton-cp4i \
          -f /work/maven-output/Dockerfile -t $(params.dockerRegistry)/tea-tekton-cp4i-ct /work/maven-output
        buildah  --storage-driver=overlay push --tls-verify=false --digestfile /tmp/image-digest \
          $(params.dockerRegistry)/tea-tekton-cp4i-ct  "docker://$(params.dockerRegistry)/tea-tekton-cp4i-ct"
        printf '%s' "$(params.dockerRegistry)/tea-tekton-cp4i-ct"
      volumeMounts:
        - mountPath: /work
          name: work
        - name: varlibcontainers
          mountPath: /var/lib/containers
  volumes:
    - name: work
      emptyDir: {}
    - name: secret-volume-2
      secret:
        secretName: jdbc-secret
    #- name: kaniko-cache
    #  persistentVolumeClaim:
    #    claimName: kaniko-cache-pvc
    - name: varlibcontainers
      persistentVolumeClaim:
        claimName: buildah-cache
